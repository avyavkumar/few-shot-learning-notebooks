{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors, datasets\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from tqdm import tqdm \n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import poisson_disc as poi\n",
    "import mosek\n",
    "# from mathutils.geometry import intersect_point_line\n",
    "\n",
    "\"\"\"\n",
    "Created on Tue May 19 14:39:25 2020\n",
    "\n",
    "@author: ilia10000\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def softmax(X, theta = 1.0, axis = None):\n",
    "  \"\"\"\n",
    "  Compute the softmax of each element along an axis of X.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  X: ND-Array. Probably should be floats.\n",
    "  theta (optional): float parameter, used as a multiplier\n",
    "      prior to exponentiation. Default = 1.0\n",
    "  axis (optional): axis to compute values along. Default is the\n",
    "      first non-singleton axis.\n",
    "\n",
    "  Returns an array the same size as X. The result will sum to 1\n",
    "  along the specified axis.\n",
    "  \"\"\"\n",
    "\n",
    "  # make X at least 2d\n",
    "  y = np.atleast_2d(X)\n",
    "\n",
    "  # find axis\n",
    "  if axis is None:\n",
    "      axis = next(j[0] for j in enumerate(y.shape) if j[1] > 1)\n",
    "\n",
    "  # multiply y against the theta parameter,\n",
    "  y = y * float(theta)\n",
    "\n",
    "  # subtract the max for numerical stability\n",
    "  y = y - np.expand_dims(np.max(y, axis = axis), axis)\n",
    "\n",
    "  # exponentiate y\n",
    "  y = np.exp(y)\n",
    "\n",
    "  # take the sum along the specified axis\n",
    "  ax_sum = np.expand_dims(np.sum(y, axis = axis), axis)\n",
    "\n",
    "  # finally: divide elementwise\n",
    "  p = y / ax_sum\n",
    "\n",
    "  # flatten if X was 1D\n",
    "  if len(X.shape) == 1: p = p.flatten()\n",
    "\n",
    "  return p\n",
    "\n",
    "class SoftKNN:\n",
    "  def __init__(self,k=None):\n",
    "    self.x=[]\n",
    "    self.y=[]\n",
    "    self.k=k\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    self.x=x\n",
    "    self.y=y\n",
    "\n",
    "  def calc_dists(self, point):\n",
    "    dists=[]\n",
    "    for prototype in self.x:\n",
    "        dist = np.linalg.norm(point-prototype)\n",
    "        dists.append(dist)\n",
    "    return dists\n",
    "\n",
    "  def calc_lab(self, dists):\n",
    "    label=np.zeros_like(self.y[0])\n",
    "    tups = zip(self.y, dists)\n",
    "    if self.k is None:\n",
    "      for prototype, dist in tups:\n",
    "        label += prototype/dist\n",
    "    else:\n",
    "      tups=list(tups)\n",
    "      res = sorted(tups, key = lambda x: x[1])[:self.k]\n",
    "      for prototype, dist in res:\n",
    "        label+=prototype/dist\n",
    "    return label\n",
    "          \n",
    "  def predict(self, point):\n",
    "    dists = self.calc_dists(point)\n",
    "    label = self.calc_lab(dists)\n",
    "    pred = np.argmax(label)\n",
    "    return pred\n",
    "\n",
    "  def probabilities(self,points):\n",
    "    preds=[]\n",
    "    for point in points:\n",
    "      dists = self.calc_dists(point)\n",
    "      label = self.calc_lab(dists)\n",
    "      preds.append(label)\n",
    "    return np.array(preds)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "start patch #4\n",
    "blender's mathutil library provides a default function to provide the closest point on line with respect to the given point, \n",
    "but the method is unstable for higher dimensions and prone to return NANs. \n",
    "https://github.com/dfelinto/blender/blob/master/source/blender/python/mathutils/mathutils_geometry.c#L774\n",
    "Writing our custom intersect_point_line() function using the above for inspiration.\n",
    "@author - avyav_kumar.singh@kcl.ac.uk    \n",
    "2022-02-12T22:10:11Z\n",
    "\"\"\"\n",
    "def intersect_point_line(point, line_point1, line_point2):\n",
    "    distance_point1_point = point - line_point1\n",
    "    distance_point2_point1 = line_point2 - line_point1\n",
    "\n",
    "    magnitude_point1_point2 = np.sum(distance_point2_point1**2)\n",
    "    dot_points = np.dot(distance_point1_point, distance_point2_point1)\n",
    "    distance = dot_points/magnitude_point1_point2 if magnitude_point1_point2 !=0 else 0\n",
    "\n",
    "    if distance < 0:\n",
    "      return line_point1\n",
    "    elif distance > 1:\n",
    "      return line_point2\n",
    "    else:\n",
    "      return line_point1 + distance_point2_point1*distance\n",
    "\"\"\"\n",
    "end patch #4\n",
    "\"\"\"\n",
    "\n",
    "def get_cmap(n, name='tab20'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "def get_projections(centroids, endpoints=[0,-1]):\n",
    "    # intersects = [list(intersect_point_line(centroid, centroids[endpoints[0]], centroids[endpoints[1]])[0]) for centroid in centroids]\n",
    "    intersects = [list(intersect_point_line(centroid, centroids[endpoints[0]], centroids[endpoints[1]])) for centroid in centroids]\n",
    "    return np.array(intersects)\n",
    "\n",
    "def dist(a,b):\n",
    "    return np.linalg.norm(a-b)\n",
    "\n",
    "def get_dists(intersects, active_classes):\n",
    "    inter = intersects[active_classes]\n",
    "    dists = [dist(inter[0],inter[i]) for i in range(len(inter))]\n",
    "    return dists\n",
    "\n",
    "def mid(a,b):\n",
    "    return (a+b)/2\n",
    "\n",
    "def get_mids(intersects, active_classes):\n",
    "    inter = intersects[active_classes]\n",
    "    mids = [mid(inter[i],inter[i+1]) for i in range(len(inter)-1)]\n",
    "    return mids\n",
    "\n",
    "def get_mid_dists(intersects, active_classes):\n",
    "    inter = intersects[active_classes]\n",
    "    mids = [mid(inter[i],inter[i+1]) for i in range(len(inter)-1)]\n",
    "    mid_dists = [dist(inter[0],mids[i]) for i in range(len(mids))] \n",
    "    return mid_dists\n",
    "\n",
    "def create_system_V4(n, mid_dists=None, tot_dist= None, endpoints=None, dists=None, var=None):\n",
    "    A=[]\n",
    "    epsilon = 1e-3\n",
    "    assert(len(mid_dists)==n-1)\n",
    "    constraints=[]\n",
    "    for i in range(len(dists)):\n",
    "        \n",
    "        vector = np.zeros(n*2)\n",
    "        vector[i] += 1./(dists[i]+epsilon-endpoints[0])\n",
    "        vector[n+i] += 1./(endpoints[1]-dists[i]+epsilon)\n",
    "        q1 = var[i]/(dists[i]+epsilon-endpoints[0])\n",
    "        q2 = var[n+i]/(endpoints[1]-dists[i]+epsilon)\n",
    "        for j in range(len(dists)):\n",
    "            if i!=j:\n",
    "                vector[j] -= 1./(dists[i]+epsilon-endpoints[0])\n",
    "                vector[n+j] -= 1./(endpoints[1]-dists[i]+epsilon)\n",
    "                q3=var[j]/(dists[i]+epsilon-endpoints[0])\n",
    "                q4=var[n+j]/(endpoints[1]-dists[i]+epsilon)\n",
    "                constraint = q1+q2>=q3+q4+epsilon*epsilon\n",
    "                constraints.append(constraint)\n",
    "        A.append(vector)\n",
    "    \n",
    "    for i in range(len(mid_dists)):\n",
    "        \n",
    "        q1 = var[i]/(mid_dists[i]-endpoints[0])\n",
    "        q2 = var[n+i]/(endpoints[1]-mid_dists[i])\n",
    "        \n",
    "        q3=var[i+1]/(mid_dists[i]-endpoints[0])\n",
    "        q4=var[n+i+1]/(endpoints[1]-mid_dists[i])\n",
    "        constraint = q1+q2==q3+q4\n",
    "        constraints.append(constraint)\n",
    "    constraints.append(var>=0)\n",
    "    constraints.append(var<=1)\n",
    "    constraints.append(sum(var[0:n])==1)\n",
    "    constraints.append(sum(var[n:])==1)\n",
    "    #A.append(np.append(np.ones(n),np.zeros(n)))\n",
    "    #A.append(np.append(np.zeros(n),np.ones(n)))\n",
    "    #A.append(np.zeros(n*2))\n",
    "    #A[-1][n-1]=1\n",
    "    #A.append(np.zeros(n*2))\n",
    "    #A[-1][2*n-1]=1\n",
    "    #b = np.ones(len(A))*101\n",
    "    b=np.zeros(len(A))\n",
    "    #b[-4]=1\n",
    "    #b[-3]=1\n",
    "    return A, b, constraints\n",
    "\n",
    "def vis_line(line, num_classes,dat, centroids, colors, return_plt=False):\n",
    "    cmap=\"tab20\"\n",
    "# print(colors)\n",
    "    for i in range(num_classes):\n",
    "        temp=dat[0][dat[1]==i]\n",
    "        x=[t[0] for t in temp]\n",
    "        y=[t[1] for t in temp]\n",
    "        if i in line:# or True:\n",
    "            plt.scatter(x,y, label=i, color=colors[i], alpha=0.5)\n",
    "            plt.scatter(np.mean(x),np.mean(y),c=\"black\")\n",
    "    plt.plot([centroids[line[0]][0],centroids[line[-1]][0]],[centroids[line[0]][1],centroids[line[-1]][1]])\n",
    "    plt.legend()\n",
    "    if return_plt:\n",
    "        return plt\n",
    "    plt.show()\n",
    "\n",
    "def line_features(line, centroids):\n",
    "    intersects=get_projections(centroids, [line[0],line[-1]])\n",
    "    dists=get_dists(intersects, line)\n",
    "    mids=get_mids(intersects, line)\n",
    "    mid_dists=get_mid_dists(intersects, line)\n",
    "    return intersects, dists, mids, mid_dists\n",
    "\n",
    "def get_line_prototypes(line, centroids):\n",
    "    n=len(line)\n",
    "    x = cp.Variable(2*n)\n",
    "    # left = cp.Parameter(nonneg=True)\n",
    "    # right = cp.Parameter(nonneg=True)\n",
    "    # left.value=0\n",
    "    # right.value = dists[-1]\n",
    "    intersects, dists, mids, mid_dists = line_features(line, centroids)\n",
    "    left=0\n",
    "    right = dists[-1]\n",
    "    #print(mid_dists)\n",
    "#     print(dists)\n",
    "    #print(right)\n",
    "    s3=create_system_V4(n, mid_dists=mid_dists, tot_dist= None, endpoints=[left,right], dists=dists,var=x)\n",
    "\n",
    "    A,b,constraints=s3\n",
    "    A=np.array(A)\n",
    "    # print(\"dists are \", dists)\n",
    "    # print(\"x is \", x)\n",
    "    # print(\"constraints are \", constraints)\n",
    "    objective = cp.Maximize(cp.sum(A@x)+cp.sum_smallest(A@x,2))\n",
    "    # constraints = [0 <= x, x <= 1, sum(x[0:5])==1, sum(x[5:10])==1]\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    result = prob.solve(solver=cp.MOSEK)\n",
    "    distX=np.array([centroids[line[0]],centroids[line[-1]]])\n",
    "    distY = np.zeros((2,len(centroids)))\n",
    "    distY[0,line], distY[1,line] = x.value[0:n], x.value[n:]\n",
    "    return distX, distY\n",
    "\n",
    "def get_dist_to_line(point, line, centroids):\n",
    "    inter = list(intersect_point_line(point, centroids[line[0]], centroids[line[-1]])[0])\n",
    "    d=dist(inter,point)\n",
    "    return d\n",
    "\n",
    "def dist_to_line(x1, y1, x2, y2, x3, y3): # x3,y3 is the point\n",
    "    px = x2-x1\n",
    "    py = y2-y1\n",
    "    norm = px*px + py*py\n",
    "    u =  ((x3 - x1) * px + (y3 - y1) * py) / float(norm)\n",
    "    if u > 1:\n",
    "        u = 1\n",
    "    elif u < 0:\n",
    "        u = 0\n",
    "    x = x1 + u * px\n",
    "    y = y1 + u * py\n",
    "    dx = x - x3\n",
    "    dy = y - y3\n",
    "    dist = (dx*dx + dy*dy)**.5\n",
    "    return dist\n",
    "\n",
    "def lineseg_dist(p, a, b):\n",
    "\n",
    "    # normalized tangent vector\n",
    "    d = np.divide(b - a, np.linalg.norm(b - a))\n",
    "\n",
    "    # signed parallel distance components\n",
    "    s = np.dot(a - p, d)\n",
    "    t = np.dot(p - b, d)\n",
    "\n",
    "    # clamped parallel distance\n",
    "    h = np.maximum.reduce([s, t, 0])\n",
    "\n",
    "    # perpendicular distance component\n",
    "    c = np.cross(p - a, d)\n",
    "\n",
    "    return np.hypot(h, np.linalg.norm(c))\n",
    "\n",
    "def dist_to_line_multiple(endpoints, x3, y3): # x3,y3 is the point\n",
    "    x1=endpoints[:,0][:,0]\n",
    "    x2=endpoints[:,1][:,0]\n",
    "    y1=endpoints[:,0][:,1]\n",
    "    y2=endpoints[:,1][:,1]\n",
    "    px = x2-x1\n",
    "    py = y2-y1\n",
    "    norm = 1.*px*px + 1.*py*py\n",
    "    u =  ((x3 - x1) * px + (y3 - y1) * py) / norm\n",
    "    u[u > 1]=1\n",
    "    u[u < 0] = 0\n",
    "    x = x1 + u * px\n",
    "    y = y1 + u * py\n",
    "    dx = x - x3\n",
    "    dy = y - y3\n",
    "    dist = (dx*dx + dy*dy)**.5\n",
    "    return dist\n",
    "\n",
    "def dist_to_line_multiple_V2(endpoints, points): # x3,y3 is the point\n",
    "    x1=endpoints[:,0][:,0]\n",
    "    x2=endpoints[:,1][:,0]\n",
    "    y1=endpoints[:,0][:,1]\n",
    "    y2=endpoints[:,1][:,1]\n",
    "    x3=points[:,0]\n",
    "    y3=points[:,1]\n",
    "    px = x2-x1\n",
    "    py = y2-y1\n",
    "    norm = 1.*px*px + 1.*py*py\n",
    "    u = (np.subtract.outer(x3,x1) * px + np.subtract.outer(y3,y1) * py) / norm\n",
    "    u[u > 1] = 1\n",
    "    u[u < 0] = 0\n",
    "    \n",
    "    x = x1 + u * px\n",
    "    y = y1 + u * py\n",
    "    dx = x - x3[:,np.newaxis]\n",
    "    dy = y - y3[:,np.newaxis]\n",
    "    dist = (dx*dx + dy*dy)**.5\n",
    "    return dist\n",
    "\n",
    "def closest_line(lines,centroids, point):\n",
    "#     print(lines)\n",
    "    dists = [dist_to_line(*centroids[line[0]], *centroids[line[1]], *point) for line in lines]\n",
    "    mindex = np.argmin(dists)\n",
    "    return lines[mindex], dists[mindex]\n",
    "\n",
    "def closest_line_multiple(lines,centroids):\n",
    "    lines=np.array(lines)\n",
    "    centroids=np.array(centroids)\n",
    "    #dists = [[dist_to_line(*centroids[line[0]], *centroids[line[1]], *point) for line in lines] for point in centroids]\n",
    "    #dists = [dist_to_line_multiple(centroids[lines], *point) for point in centroids]\n",
    "    dists = dist_to_line_multiple_V2(centroids[lines], centroids) \n",
    "    dists=np.array(dists)\n",
    "    mindex = np.argmin(dists, axis=1)\n",
    "    \"\"\"\n",
    "    start patch #12\n",
    "    np.choose is unstable for higher dimensionalities\n",
    "    @author - avyav_kumar.singh@kcl.ac.uk    \n",
    "    2022-02-26T19:59:01Z\n",
    "    \"\"\"\n",
    "    required_array = dists[range(len(mindex)), mindex]\n",
    "    return lines[mindex], np.sum(required_array)\n",
    "    \"\"\"\n",
    "    end patch #12\n",
    "    \"\"\"\n",
    "\n",
    "def ccw(A,B,C):\n",
    "    return (C[1]-A[1]) * (B[0]-A[0]) > (B[1]-A[1]) * (C[0]-A[0])\n",
    "\n",
    "def ccw_multi(A,B,C):\n",
    "    return (C[:,1]-A[:,1]) * (B[:,0]-A[:,0]) > (B[:,1]-A[:,1]) * (C[:,0]-A[:,0])\n",
    "\n",
    "# Return true if line segments AB and CD intersect\n",
    "def intersecting(A,B,C,D):\n",
    "    return ccw(A,C,D) != ccw(B,C,D) and ccw(A,B,C) != ccw(A,B,D)\n",
    "\n",
    "def intersecting_multi(A,B,C,D):\n",
    "    return np.any((ccw_multi(A,C,D)!= ccw_multi(B,C,D))*(ccw_multi(A,B,C) != ccw_multi(A,B,D)))\n",
    "\n",
    "def any_intersect(lines, centroids, combos):\n",
    "    if intersecting_multi(centroids[lines[combos[:,0]]][:,0],centroids[lines[combos[:,0]]][:,1],centroids[lines[combos[:,1]]][:,0],centroids[lines[combos[:,1]]][:,1]):\n",
    "        return True       \n",
    "    return False\n",
    "\n",
    "def line_order(centroids, active_classes):\n",
    "    intersects=get_projections(centroids, endpoints=[active_classes[0],active_classes[1]])\n",
    "    dists=get_dists(intersects, active_classes)\n",
    "    return active_classes[np.argsort(dists)]\n",
    "\n",
    "def get_pairwise_dists(centroids, active_classes):\n",
    "    active_locs=np.array(centroids)[np.array(active_classes)]\n",
    "    dists = np.linalg.norm(active_locs[:, None, :] - active_locs[None, :, :], axis=-1)\n",
    "    return dists\n",
    "\n",
    "def line_order_no_endpoints(centroids, active_classes):\n",
    "    dists = get_pairwise_dists(centroids, active_classes)\n",
    "    endpoints=np.argmax(dists)\n",
    "    endpoints = np.unravel_index(endpoints, dists.shape)\n",
    "    endpoints=[active_classes[endpoints[0]],active_classes[endpoints[1]]]\n",
    "    intersects=get_projections(centroids, endpoints=endpoints)\n",
    "    start=intersects[endpoints[0]]\n",
    "    intersects=intersects[active_classes]\n",
    "    dists2 = [dist(start,intersects[i]) for i in range(len(intersects))]\n",
    "    return active_classes[np.argsort(dists2)]\n",
    "\n",
    "def find_lines_brute(centroids, k=3):\n",
    "    num_classes = len(centroids)\n",
    "    \"\"\"\n",
    "    start patch #2\n",
    "    when two classes are required with only 1 line to be fitted, return the trivial line\n",
    "    @author - avyav_kumar.singh@kcl.ac.uk    \n",
    "    2022-01-28T12:50:19Z\n",
    "    \"\"\"\n",
    "    if num_classes == 2 and k == 1:\n",
    "      full_lines = [np.array([0, 1])]\n",
    "      return full_lines\n",
    "    \"\"\"\n",
    "    end patch #2\n",
    "    \"\"\"\n",
    "    centroids=np.array(centroids)\n",
    "    lines=list(combinations(range(num_classes),2))\n",
    "    lines=np.array(lines)\n",
    "    triple_lines=np.array(list(combinations(range(len(lines)),k)))\n",
    "    index_lines=np.array(lines[triple_lines])\n",
    "    index_centroids=np.array(centroids)[index_lines]\n",
    "    total_dists=[]\n",
    "    all_nearest=[]\n",
    "    lines_intersect=[]\n",
    "    combos=np.array(list(combinations(range(k),2)))\n",
    "    for triplex in range(len(triple_lines)):\n",
    "        triple_line=index_centroids[triplex]#[centroids[[line]] for line in index_lines[triplex]]\n",
    "        nearest_array,total_dist = closest_line_multiple(index_lines[triplex],centroids)\n",
    "        all_nearest.append(nearest_array)\n",
    "        total_dists.append(total_dist)\n",
    "        lines_intersect.append(any_intersect(index_lines[triplex],centroids,combos))\n",
    "    lines_intersect=np.array(lines_intersect)\n",
    "    triple_lines=np.array(triple_lines)\n",
    "    total_dists=np.array(total_dists)\n",
    "    all_nearest=np.array(all_nearest)\n",
    "    triple_lines=triple_lines[lines_intersect==False]\n",
    "    total_dists=total_dists[lines_intersect==False]\n",
    "    all_nearest=all_nearest[lines_intersect==False]\n",
    "    mindex = np.argmin(total_dists)\n",
    "    top_lines_endpoints=lines[[triple_lines[mindex]]]\n",
    "    full_lines=list(np.copy(top_lines_endpoints))\n",
    "    for i in range(len(all_nearest[mindex])):\n",
    "        for j in range(len(top_lines_endpoints)):\n",
    "            if np.all(all_nearest[mindex][i] == top_lines_endpoints[j]):\n",
    "                if i not in full_lines[j]:\n",
    "                    full_lines[j]=list(full_lines[j])+[i]\n",
    "    return full_lines         \n",
    "\n",
    "#Find best line, then find best non-intersecting lines\n",
    "def find_lines_greedy1(centroids,k=3):\n",
    "    num_classes = len(centroids)\n",
    "    \"\"\"\n",
    "    start patch #3\n",
    "    when two classes are required with only 1 line to be fitted, return the trivial line\n",
    "    @author - avyav_kumar.singh@kcl.ac.uk    \n",
    "    2022-01-28T12:50:19Z\n",
    "    \"\"\"\n",
    "    if num_classes == 2 and k == 1:\n",
    "      full_lines = [np.array([0, 1])]\n",
    "      return full_lines\n",
    "    \"\"\"\n",
    "    end patch #3\n",
    "    \"\"\"\n",
    "    centroids=np.array(centroids)\n",
    "    lines=list(combinations(range(num_classes),2))\n",
    "    lines=np.array(lines)\n",
    "    triple_lines=np.array(list(combinations(range(len(lines)),k)))\n",
    "    index_lines=np.array(lines[triple_lines])\n",
    "    index_centroids=np.array(centroids)[index_lines]\n",
    "    total_dists=[]\n",
    "    all_nearest=[]\n",
    "    lines_intersect=[]\n",
    "\n",
    "    combos=np.array(list(combinations(range(k),2)))\n",
    "    for triplex in range(len(triple_lines)):\n",
    "        triple_line=index_centroids[triplex]#[centroids[[line]] for line in index_lines[triplex]]\n",
    "        nearest_array,total_dist = closest_line_multiple(index_lines[triplex],centroids)\n",
    "        all_nearest.append(nearest_array)\n",
    "        total_dists.append(total_dist)\n",
    "        lines_intersect.append(any_intersect(index_lines[triplex],centroids,combos))\n",
    "    lines_intersect=np.array(lines_intersect)\n",
    "    triple_lines=np.array(triple_lines)\n",
    "    total_dists=np.array(total_dists)\n",
    "    all_nearest=np.array(all_nearest)\n",
    "    triple_lines=triple_lines[lines_intersect==False]\n",
    "    total_dists=total_dists[lines_intersect==False]\n",
    "    all_nearest=all_nearest[lines_intersect==False]\n",
    "    mindex = np.argmin(total_dists)\n",
    "    top_lines_endpoints=lines[[triple_lines[mindex]]]\n",
    "    full_lines=list(np.copy(top_lines_endpoints))\n",
    "    for i in range(len(all_nearest[mindex])):\n",
    "        for j in range(len(top_lines_endpoints)):\n",
    "            if np.all(all_nearest[mindex][i] == top_lines_endpoints[j]):\n",
    "                if i not in full_lines[j]:\n",
    "                    full_lines[j]=list(full_lines[j])+[i]\n",
    "    return full_lines  \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "result1=None\n",
    "\n",
    "def point_on_line(p, a, b):\n",
    "    ap = p - a\n",
    "    ab = b - a\n",
    "    t = np.dot(ap, ab) / np.dot(ab, ab)\n",
    "    # if you need the the closest point belonging to the segment\n",
    "    t = max(0, min(1, t))\n",
    "    result = a + t * ab\n",
    "    return result\n",
    "\n",
    "def dist_to_line_multiD(point, A, B):\n",
    "    proj=point_on_line(point, A, B)\n",
    "    length = dist(A,B)\n",
    "#     distA = dist(proj,A)\n",
    "#     distB = dist(proj,B)\n",
    "#     if distA>length or distB>length:\n",
    "#         return min(distA,distB)\n",
    "    return dist(proj,point)\n",
    "\n",
    "def closest_line_multiD(lines,centroids):\n",
    "    lines=np.array(lines)\n",
    "    centroids=np.array(centroids)\n",
    "    dists = [[dist_to_line_multiD(point,centroids[line[0]], centroids[line[1]]) for line in lines] for point in centroids]\n",
    "    #dists = [dist_to_line_multiple(centroids[lines], *point) for point in centroids]\n",
    "    #dists = dist_to_line_multiple_V2(centroids[lines], centroids) \n",
    "    dists=np.array(dists)\n",
    "    mindex = np.argmin(dists, axis=1)\n",
    "    \"\"\"\n",
    "    start patch #13\n",
    "    np.choose is unstable for higher dimensionalities\n",
    "    @author - avyav_kumar.singh@kcl.ac.uk    \n",
    "    2022-02-26T19:59:01Z\n",
    "    \"\"\"\n",
    "    required_array = dists[range(len(mindex)), mindex]\n",
    "    return lines[mindex], np.sum(required_array)\n",
    "    \"\"\"\n",
    "    end patch #13\n",
    "    \"\"\"\n",
    "\n",
    "def find_lines_R(dat,centroids,k=5, max_diff=0.1):\n",
    "  x=np.array(dat[0][:,0])\n",
    "  y=np.array(dat[0][:,1])\n",
    "  labels = dat[1]\n",
    "  df=pd.DataFrame(np.array([x,y,labels]).transpose())\n",
    "  df.columns=[[\"X\", \"Y\", \"My Hopes And Dreams\"]]\n",
    "  #result1=[]\n",
    "  %R -i df -i k -i max_diff -o result1 result1 <- recursive_reg(df[,-3], df[,3]+1, k = k, max_diff = max_diff)\n",
    "  lines=[list(r) for r in result1]\n",
    "  #print(lines)\n",
    "  lines=np.array([[line[0],line[-1]] for line in lines])-1\n",
    "  nearest_array,total_dist = closest_line_multiple(lines,centroids)\n",
    "  full_lines=[list(line) for line in lines]\n",
    "  for i in range(len(nearest_array)):\n",
    "      for j in range(len(lines)):\n",
    "          if np.all(nearest_array[i] == lines[j]):\n",
    "              if i not in full_lines[j]:\n",
    "                  full_lines[j]=list(full_lines[j])+[i]\n",
    "  \n",
    "  return(full_lines)  \n",
    "\n",
    "\"\"\"\n",
    "patch #3\n",
    "fix input parameters to make the data and labels distinction clear\n",
    "@author - avyav_kumar.singh@kcl.ac.uk\n",
    "2022-02-02T20:09:43Z\n",
    "\"\"\"\n",
    "def find_lines_R_multiD(dat, labels, centroids, dims = 2, k=5, max_diff=1e-1):\n",
    "  cols=[]\n",
    "  for dim in range(dims):\n",
    "    x=np.array(dat[:,dim])\n",
    "    cols.append(x)\n",
    "  df=pd.DataFrame(np.array([*cols,labels]).transpose())\n",
    "  \n",
    "  \"\"\"\n",
    "  start patch #1\n",
    "  fix naming of columns in the data frame\n",
    "  @author - avyav_kumar.singh@kcl.ac.uk\n",
    "  reference - https://stackoverflow.com/a/62033656\n",
    "  2022-01-27T17:25:50Z\n",
    "  \"\"\"\n",
    "  df.columns=[*[str(i) for i in range(dims)], \"My Hopes And Dreams\"]\n",
    "  df[\"My Hopes And Dreams\"] = df[\"My Hopes And Dreams\"].apply(np.int64)\n",
    "  \"\"\"\n",
    "  end patch #1\n",
    "  \"\"\"\n",
    "  \n",
    "  # print(df)\n",
    "  #result1=[]\n",
    "  %R -i df -i k -i max_diff -i dims -o result1 result1 <- recursive_reg(as.matrix(df[,-(dims+1)]), df[,dims+1]+1, k = k, max_diff = max_diff)\n",
    "  lines=[list(r) for r in result1]\n",
    "  #print(lines)\n",
    "  lines=np.array([[line[0],line[-1]] for line in lines])-1\n",
    "  nearest_array,total_dist = closest_line_multiD(lines,centroids)\n",
    "  full_lines=[list(line) for line in lines]\n",
    "  for i in range(len(nearest_array)):\n",
    "      for j in range(len(lines)):\n",
    "          if np.all(nearest_array[i] == lines[j]):\n",
    "              if i not in full_lines[j]:\n",
    "                  full_lines[j]=list(full_lines[j])+[i]\n",
    "  \n",
    "  return(full_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(MASS)\n",
    "\n",
    "xwx <- function(xtx_in, x, w) {\n",
    "  \n",
    "  # computes inverse of Z'Z, \n",
    "  # where Z = rows of X with non-zero weight\n",
    "  \n",
    "  # xtx_in = inverse of X'X\n",
    "  # x = n x p covariate matrix X\n",
    "  # w = length n vector of zero-one weight\n",
    "  # w cannot be all-zero\n",
    "  if (sum(w) == 0) stop('All rows have zero weight.')\n",
    "  \n",
    "  \n",
    "  \n",
    "  # case 1: no zero-weights; same as inverse of X'X\n",
    "  if (prod(w) == 1) return(xtx_in)\n",
    "  \n",
    "  # case 2: number of zero-weight rows >= p\n",
    "  # invert directly\n",
    "  else if (sum(w) < ncol(x)) {\n",
    "    z1 <- x[w == 1, , drop = F]\n",
    "    return(ginv(t(z1) %*% z1))\n",
    "  }\n",
    "  \n",
    "  # case 3: number of zero-weight rows < p\n",
    "  # use woodbury identity to invert a smaller matrix\n",
    "  else {\n",
    "    z0 <- x[w == 0, , drop = F]\n",
    "    A <- z0 %*% xtx_in\n",
    "    B <- -A %*% t(z0)\n",
    "    diag(B) <- diag(B) + 1\n",
    "    return(xtx_in + t(A) %*% ginv(B) %*% A)\n",
    "  }\n",
    "}\n",
    "\n",
    "xwy <- function(x, y, w) {\n",
    "  \n",
    "  # computes Z'y,\n",
    "  # where Z are the rows of x with non-zero weight\n",
    "  \n",
    "  # x = n x p covariate matrix X\n",
    "  # y = length n vector\n",
    "  # w = length n vector of zero-one weight\n",
    "  # w cannot be all-zero\n",
    "  if (sum(w) == 0) stop('All rows have zero weight.')\n",
    "  \n",
    "  # set zero-weight entries of y to be zero\n",
    "  y[w == 0] <- 0\n",
    "  return(t(x) %*% y)\n",
    "}\n",
    "\n",
    "\n",
    "#library(MASS)\n",
    "#x <- matrix(runif(5 * 1), 5, 1)\n",
    "#xtx_in <- solve(t(x) %*% x)\n",
    "#w <- c(1,0,0,0,0)\n",
    "#y <- runif(5)\n",
    "\n",
    "#xwx(xtx_in, x, w)\n",
    "#xwy(x, y, w)\n",
    "#xwx(xtx_in, x, w) %*% xwy(x, y, w)\n",
    "\n",
    "beta_w <- function(xtx_in, x, y, w) {\n",
    "  xwx(xtx_in, x, w) %*% xwy(x, y, w)\n",
    "}\n",
    "\n",
    "two_norm <- function(a, b) {\n",
    "  sqrt(sum((a - b)^2))\n",
    "}\n",
    "\n",
    "\n",
    "group_classes <- function(data, label, k) {\n",
    "  mu <- t(sapply(unique(label), function(ii) {\n",
    "    colMeans(data[label == ii, , drop = F])\n",
    "    }))\n",
    "  \n",
    "  mu_dist <- dist(mu)\n",
    "  cluster <- cutree(hclust(mu_dist, method = \"complete\"), k = k)\n",
    "  \n",
    "  mu2 <- t(sapply(unique(cluster), function(ii) {\n",
    "    colMeans(mu[cluster == ii, , drop = F])\n",
    "  }))\n",
    "  \n",
    "  dist2 <- as.matrix(dist(mu2))\n",
    "  \n",
    "  jj <- 1\n",
    "  while (jj <= length(unique(cluster))) {\n",
    "    #print(length(unique(cluster)))\n",
    "    #print(jj)\n",
    "    if (table(cluster)[jj] == 1) {\n",
    "      new_cluster <- which(rank(dist2[jj, ]) == 2)\n",
    "      cluster[cluster == jj] <- new_cluster\n",
    "    }\n",
    "    jj <- jj + 1\n",
    "  }\n",
    "  # print(cluster)\n",
    "  return(cluster)\n",
    "}\n",
    "\n",
    "furthest_classes <- function(data, label, classes) {\n",
    "  mu <- t(sapply(classes, function(ii) {\n",
    "    colMeans(data[label == ii,  , drop = F])\n",
    "  }))\n",
    "  mu_dist <- as.matrix(dist(mu))\n",
    "  furthest <- which(mu_dist == max(mu_dist), arr.ind = T)[1, ]\n",
    "  return(classes[furthest])\n",
    "}\n",
    "\n",
    "add_classes <- function(data, label, classes, max_diff = 1.5) {\n",
    "  \n",
    "  # two furthest-apart classes in the group\n",
    "  # we initially fit a line that pierces through both of their centroids\n",
    "  furthest <- furthest_classes(data, label, classes)\n",
    "  rest <- classes[!(classes %in% furthest)]\n",
    "  \n",
    "  x <- cbind(1, data[, -ncol(data)])\n",
    "  y <- data[, ncol(data)]\n",
    "  \n",
    "  xtx_in <- ginv(t(x) %*% x)\n",
    "  w <- ifelse(label %in% furthest, 1, 0)\n",
    "  beta <- beta_w(xtx_in, x, y, w)\n",
    "\n",
    "  while (length(rest) > 0) {\n",
    "    \n",
    "    # for the remaining classes, fit a regression line with it and\n",
    "    # only classes currently in 'furthest' list\n",
    "    beta_list <- lapply(rest, function(ii) {\n",
    "      w <- ifelse(label %in% c(ii, furthest), 1, 0)\n",
    "      return(beta_w(xtx_in, x, y, w))\n",
    "    })\n",
    "    \n",
    "    # compare the distance between the regression line with the initial two furthest classes\n",
    "    # and the newly fitted regression line\n",
    "    distance <- sapply(beta_list, function(a) two_norm(a, beta))\n",
    "    \n",
    "    # stop if the smallest difference between the two regression lines is \n",
    "    # greater than the max tolerance\n",
    "    if (all(distance > max_diff)) {\n",
    "      rest <- integer(0)\n",
    "    } else {\n",
    "      \n",
    "      # otherwise, include the class whose addition resulted in the smallest change\n",
    "      # in the original regression line\n",
    "      add <- which.min(distance)[1]\n",
    "      furthest <- c(furthest, rest[add])\n",
    "      rest <- rest[-add]\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(list(group = unique(furthest), line = beta))\n",
    "}\n",
    "\n",
    "\n",
    "order_classes <- function(data, label, group) {\n",
    "  # first two elements in group must be the furthest away.\n",
    "  # this will be the case if group comes from recursive regression\n",
    "  \n",
    "  if (length(group) == 1) {\n",
    "    return(group)\n",
    "  } else {\n",
    "    temp <- sapply(group[-1], function(ii) {\n",
    "      a <- colMeans(data[label == group[1], , drop = F])\n",
    "      b <- colMeans(data[label == ii, , drop = F])\n",
    "      return(sum((a - b)^2))\n",
    "    })\n",
    "    return(c(group[1], group[-1][order(temp)]))\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "recursive_reg <- function(data, label, k, max_diff = 1e-1, keep_all = T) {\n",
    "  \n",
    "  # group the class-wise centroids into k groups\n",
    "  init_group <- group_classes(data, label, k)\n",
    "  k_new <- length(unique(init_group))\n",
    "  \n",
    "  #if (k_new == 1) {\n",
    "  #  val <- list(group = order_classes(data, label, 1),\n",
    "  #              line = lm())\n",
    "  #}\n",
    "  # for each of the k groups, find a line that incorporates\n",
    "  # as many of the classes in that group as possible\n",
    "  val <- lapply(sort(unique(init_group)), function(ii) {\n",
    "    classes <- which(init_group == ii)\n",
    "    # print(classes)\n",
    "    if (keep_all) {\n",
    "      temp <- add_classes(data, label, classes, max_diff)\n",
    "      temp$group <- order_classes(data, label, temp$group)\n",
    "      return(temp$group)\n",
    "    } else {\n",
    "      if (length(unique(classes)) == 1) {\n",
    "        return(NULL)\n",
    "      } else {\n",
    "        temp <- add_classes(data, label, classes, max_diff)\n",
    "        temp$group <- order_classes(data, label, temp$group)\n",
    "        return(temp$group)\n",
    "      }\n",
    "    }\n",
    "    #add_classes(data, label, classes, max_diff)\n",
    "    #if (length(unique(classes)) == 1) {\n",
    "    #  return(NULL)\n",
    "    #} else {\n",
    "    #  add_classes(data, label, classes, max_diff)\n",
    "    #}\n",
    "  })\n",
    "  \n",
    "  if (keep_all) {\n",
    "    # if keep_all = T, keep lines from  single classes\n",
    "    return(val)\n",
    "  } else {\n",
    "    # If keep_all = F, filter out groups with only one class\n",
    "    return(val[lengths(val) != 0])\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
